{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOyCwlt4GEskeAnAUjGUb/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikshitagchiliveri/SENTIMENT-ANALYSIS-OF-THE-CLOTHING-REVIEWS/blob/main/Copy_of_IA_AIEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING PANDAS LIBRABRY**"
      ],
      "metadata": {
        "id": "Gh6LSRJAIAW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK6eZZnSGhjD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA LOADING**"
      ],
      "metadata": {
        "id": "uHGtlZ2ZIN6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Womens Clothing E-Commerce Reviews.csv')"
      ],
      "metadata": {
        "id": "ewD0A9zLG5Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "xM-S6RLlG-hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHECKING FOR THE MISSING VALUES ON THE DATAFRAME**"
      ],
      "metadata": {
        "id": "nd1Ho3QkMrWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "2zNWItatISQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HANDLING THE MISSING VALUES**"
      ],
      "metadata": {
        "id": "A-revJTLM3VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Title'].fillna(\"No Title\", inplace=True)\n",
        "df['Review Text'].fillna(\"No Review\", inplace=True)\n",
        "df['Division Name'].fillna(\"Unknown\", inplace=True)\n",
        "df['Department Name'].fillna(\"Unknown\", inplace=True)\n",
        "df['Class Name'].fillna(\"Unknown\", inplace=True)"
      ],
      "metadata": {
        "id": "FUgKb4U9IZ_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1YV6JGHqJEmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3NKgwTRSJHOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x=df['Rating'], palette=\"viridis\")\n",
        "plt.title(\"Distribution of Ratings\")\n",
        "plt.xlabel(\"Ratings (1 to 5)\")\n",
        "plt.ylabel(\"Count of Reviews\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u2Yu94d_JnJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Recommended IND'].value_counts().plot.pie(autopct='%1.1f%%', colors=['lightcoral', 'lightblue'], labels=['Not Recommended', 'Recommended'])\n",
        "plt.title(\"Product Recommendation Percentage\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ERX1uVLJpDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "GSFcOTRwJ3Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(df['Review Text'].dropna())\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Most Common Words in Reviews\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7X9tClPxJuRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "wHRZd6A-J965"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['Review Text'].dropna().apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['Sentiment'], bins=20, kde=True, color='purple')\n",
        "plt.title(\"Distribution of Sentiment Scores\")\n",
        "plt.xlabel(\"Sentiment Score (-1 to 1)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eWBq32NsJzz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['Age'], bins=30, kde=True, color=\"green\")\n",
        "plt.title(\"Distribution of Customer Ages\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uiYzK1w6J7jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review Text'] = df['Review Text'].astype(str)  # Convert non-string values\n",
        "text = ' '.join(df['Review Text'].dropna().tolist()).lower()"
      ],
      "metadata": {
        "id": "2x5xjSMIKEDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "_y5NickSKI60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "nltk_data_path = os.path.expanduser('~/nltk_data')\n",
        "if os.path.exists(nltk_data_path):\n",
        "    shutil.rmtree(nltk_data_path)  # Delete old data\n",
        "\n",
        "# Reinstall necessary packages\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "WLexDUriKwpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "id": "h5O28RmoK0zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "metadata": {
        "id": "FddeRhqSLGkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Download stopwords and tokenizer if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Ensure the column exists and is a string\n",
        "df['Review Text'] = df['Review Text'].astype(str)\n",
        "\n",
        "# Combine all reviews into a single text corpus\n",
        "text = ' '.join(df['Review Text'].dropna()).lower()\n",
        "\n",
        "# Tokenize words and remove stopwords & non-alphabetic words\n",
        "words = word_tokenize(text)\n",
        "filtered_words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]\n",
        "\n",
        "# Count the 20 most common words\n",
        "word_counts = Counter(filtered_words).most_common(20)\n",
        "top_words, top_counts = zip(*word_counts)\n",
        "\n",
        "# Plot the word frequency\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=list(top_words), y=list(top_counts), palette=\"magma\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Top 20 Most Frequent Words in Reviews\")\n",
        "plt.xlabel(\"Words\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1KAOovx1LIdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "vUB4Yt4LLL_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "nltk_data_path = os.path.expanduser('~/nltk_data')\n",
        "if os.path.exists(nltk_data_path):\n",
        "    shutil.rmtree(nltk_data_path)  # Delete old data\n",
        "\n",
        "# Reinstall necessary packages\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "Ph9yYSkkLVNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk.data.path.append('/usr/local/nltk_data')\n",
        "nltk.download('stopwords', download_dir='/usr/local/nltk_data')\n"
      ],
      "metadata": {
        "id": "TdEtYTrdLa4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back to a sentence\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to 'Review Text' column\n",
        "df['Cleaned_Review'] = df['Review Text'].apply(lambda x: preprocess_text(str(x)))\n",
        "\n",
        "df[['Review Text', 'Cleaned_Review']].head()\n"
      ],
      "metadata": {
        "id": "Dokgw-ihMQ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # Limit to top 1000 features\n",
        "X = vectorizer.fit_transform(df['Cleaned_Review'])\n",
        "\n",
        "# Convert to a DataFrame for better visualization\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display a sample\n",
        "tfidf_df.head()\n"
      ],
      "metadata": {
        "id": "cYhZx-FbLfDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def get_sentiment(text):\n",
        "    return TextBlob(text).sentiment.polarity  # Returns a value between -1 and 1\n",
        "\n",
        "df['Sentiment'] = df['Cleaned_Review'].apply(get_sentiment)\n",
        "\n",
        "# Display a sample of sentiment scores\n",
        "df[['Review Text', 'Sentiment']].head()"
      ],
      "metadata": {
        "id": "IazS56kkMNus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"processed_reviews.csv\", index=False)"
      ],
      "metadata": {
        "id": "OLaf54ucMVwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}